<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Train &mdash; MapReader 0.3.3 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Post-process" href="Post-process.html" />
    <link rel="prev" title="Annotate" href="Annotate.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MapReader
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Install.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Input-guidance.html">Input guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Input-guidance.html#preparing-your-map-corpus">Preparing your map corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Input-guidance.html#preparing-your-metadata">Preparing your metadata</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="User-guide.html">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Download.html">Download</a></li>
<li class="toctree-l2"><a class="reference internal" href="Load.html">Load</a></li>
<li class="toctree-l2"><a class="reference internal" href="Annotate.html">Annotate</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#load-data">Load data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prepare-datasets">Prepare datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-a-sampler">Define a sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-batches-dataloader">Create batches (DataLoader)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#load-a-pytorch-model">Load a PyTorch model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#define-learning-rates-and-initialise-optimiser-and-scheduler">Define learning rates and initialise optimiser and scheduler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#train-fine-tune-your-model">Train/fine-tune your model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#plot-metrics">Plot metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inference">Inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Post-process.html">Post-process</a></li>
<li class="toctree-l2"><a class="reference internal" href="Worked-examples.html">Worked examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://dl.acm.org/doi/10.1145/3557919.3565812">MapReader Paper</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MapReader</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="User-guide.html">User Guide</a></li>
      <li class="breadcrumb-item active">Train</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/User-guide/Train.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="train">
<h1>Train<a class="headerlink" href="#train" title="Permalink to this heading"></a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#load-data" id="id1">Load data</a></p>
<ul>
<li><p><a class="reference internal" href="#prepare-datasets" id="id2">Prepare datasets</a></p></li>
<li><p><a class="reference internal" href="#define-a-sampler" id="id3">Define a sampler</a></p></li>
<li><p><a class="reference internal" href="#create-batches-dataloader" id="id4">Create batches (DataLoader)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#load-a-pytorch-model" id="id5">Load a PyTorch model</a></p>
<ul>
<li><p><a class="reference internal" href="#define-learning-rates-and-initialise-optimiser-and-scheduler" id="id6">Define learning rates and initialise optimiser and scheduler</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#train-fine-tune-your-model" id="id7">Train/fine-tune your model</a></p>
<ul>
<li><p><a class="reference internal" href="#plot-metrics" id="id8">Plot metrics</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#inference" id="id9">Inference</a></p></li>
</ul>
</nav>
<p>Once you have annotated images, you can then use these to train/fine-tune a CV (Computer Vision) classifier.</p>
<section id="load-data">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Load data</a><a class="headerlink" href="#load-data" title="Permalink to this heading"></a></h2>
<p>First, load in your annotations using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mapreader</span> <span class="kn">import</span> <span class="n">loadAnnotations</span>

<span class="n">annotated_images</span><span class="o">=</span><span class="n">loadAnnotations</span><span class="p">()</span>
<span class="n">annotated_images</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./path/to/annotations.csv&quot;</span><span class="p">,</span> <span class="n">path2dir</span><span class="o">=</span><span class="s1">&#39;./path/to/images/&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>e.g.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">=</span><span class="n">loadAnnotations</span><span class="p">()</span>
<span class="n">annotated_images</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./annotations_one_inch/rail_space_#rw#.csv&quot;</span><span class="p">,</span> <span class="n">path2dir</span><span class="o">=</span><span class="s1">&#39;./maps/slice_50_50&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>To view the data loaded in from your <code class="docutils literal notranslate"><span class="pre">.csv</span></code>, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">annotations</span>
</pre></div>
</div>
<p>And, to view a summary of your annotations, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">annotated_images</span><span class="p">)</span>
</pre></div>
</div>
<p>To align with python indexing, you may want to shift your labels so they start at 0. This can be done using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">adjust_label</span><span class="p">(</span><span class="n">shiftby</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then view a sample of your annotated images using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">show_image_labels</span><span class="p">(</span><span class="n">tar_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/show_image_labels_10.png"><img alt="../_images/show_image_labels_10.png" src="../_images/show_image_labels_10.png" style="width: 400px;" /></a>
<p>By default, this will show you 10 images but this can be changed by specifying <code class="docutils literal notranslate"><span class="pre">num_sample</span></code>.</p>
<p>You can also view specific images from their indices using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">indx</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/show_image.png"><img alt="../_images/show_image.png" src="../_images/show_image.png" style="width: 400px;" /></a>
<p>Before training your CV classifier, you first need to split your annotated images into a ‘train’, ‘validate’ and ‘test’ sets.
MapReader uses a stratified method to do this, such that each set contains approximately the same percentage of samples of each target label as the original set.</p>
<p>To split your annotated images into dataframes, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">split_annotations</span><span class="p">()</span>
</pre></div>
</div>
<p>By default, your annotated images will be split as follows:</p>
<blockquote>
<div><p>70% train
15% validate
15% test</p>
</div></blockquote>
<p>However, these ratios can be changed by specifying <code class="docutils literal notranslate"><span class="pre">frac_train</span></code>, <code class="docutils literal notranslate"><span class="pre">frac_val</span></code> and <code class="docutils literal notranslate"><span class="pre">fract_test</span></code>.</p>
<p>e.g. :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">split_annotations</span><span class="p">(</span><span class="n">frac_train</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">frac_val</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">frac_test</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then check how many annotated images are in each set by checking the value counts of your dataframes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_images</span><span class="o">.</span><span class="n">train</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">annotated_images</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">annotated_images</span><span class="o">.</span><span class="n">test</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<section id="prepare-datasets">
<h3><a class="toc-backref" href="#id2" role="doc-backlink">Prepare datasets</a><a class="headerlink" href="#prepare-datasets" title="Permalink to this heading"></a></h3>
<p>Before using your images in training, validation or inference, you will first want to define some transformations and prepare your data.
This can be done using the <code class="docutils literal notranslate"><span class="pre">patchTorchDataset</span></code> class.</p>
<p>e.g. :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mapreader</span> <span class="kn">import</span> <span class="n">patchTorchDataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">resize</span><span class="o">=</span><span class="mi">224</span>
<span class="n">normalize_mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]</span> <span class="c1"># ImageNet means</span>
<span class="n">normalize_std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span> <span class="c1"># ImageNet stds</span>

<span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">resize</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">normalize_mean</span><span class="p">,</span><span class="n">normalize_std</span><span class="p">)])</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">patchTorchDataset</span><span class="p">(</span><span class="n">annotated_images</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">data_transforms</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">patchTorchDataset</span><span class="p">(</span><span class="n">annotated_images</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="n">data_transforms</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">patchTorchDataset</span><span class="p">(</span><span class="n">annotated_images</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">data_transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>This produces three datasets (<code class="docutils literal notranslate"><span class="pre">train_dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">val_dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">test_dataset</span></code>), ready for use, which can be viewed as dataframes using the <code class="docutils literal notranslate"><span class="pre">patchframe</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">your_dataset</span><span class="o">.</span><span class="n">patchframe</span>
</pre></div>
</div>
</section>
<section id="define-a-sampler">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Define a sampler</a><a class="headerlink" href="#define-a-sampler" title="Permalink to this heading"></a></h3>
<p>To account for inbalanced datasets, you may also want to define a sampler with weights inversely proportional to the number of instances of each label within a set.
This ensures, when training and validating your model, each batch is ~ representative of the whole set.
To do this, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">train_label_count</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">patchframe</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">val_label_count</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="o">.</span><span class="n">patchframe</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample_count</span><span class="p">))</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">train_label_count</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">patchframe</span><span class="p">))</span>
<span class="n">val_sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">val_label_count</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataset</span><span class="o">.</span><span class="n">patchframe</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="create-batches-dataloader">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Create batches (DataLoader)</a><a class="headerlink" href="#create-batches-dataloader" title="Permalink to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">MapReader</span></code>’s <code class="docutils literal notranslate"><span class="pre">classifier</span></code> class is xxxxx.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mapreader</span> <span class="kn">import</span> <span class="n">classifier</span>

<span class="n">my_classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">()</span>
</pre></div>
</div>
<p>To prepare your data for training, <a class="reference external" href="https://pytorch.org/">PyTorch</a> uses a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to create shuffled batches of data from each set.
To load datasetsto your classifer, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">add2dataloader</span><span class="p">(</span><span class="n">your_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, your batch sizes will be set to 16 and no sampler will be used when creating them.
This can be changed by specifying <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">sampler</span></code>.</p>
<p>e.g. :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span>

<span class="n">my_classifier</span><span class="o">.</span><span class="n">add2dataloader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also name your set using the <code class="docutils literal notranslate"><span class="pre">set_name</span></code> argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">code</span> <span class="p">::</span> <span class="n">python</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span>

<span class="n">my_classifier</span><span class="o">.</span><span class="n">add2dataloader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">sest_name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">)</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">add2dataloader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">val_sampler</span><span class="p">)</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">add2dataloader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<p>To see information about your datasets, batches and classes (labelled groups), use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">dataset_sizes</span>
</pre></div>
</div>
<p>and</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">batch_info</span><span class="p">()</span>
</pre></div>
</div>
<p>and</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">print_classes_dl</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">print_classes_dl</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">print_classes_dl</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This only works if you have specified <code class="docutils literal notranslate"><span class="pre">set_name</span></code> when adding your datasets to the dataloader</p>
</div>
<p>You may also want to set <code class="docutils literal notranslate"><span class="pre">class_names</span></code> to help with human-readability. This is done by defining a dictionary mapping each label to a new name.</p>
<p>e.g. :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s2">&quot;No&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s2">&quot;railspace&quot;</span><span class="p">}</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">set_classnames</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>
<span class="n">my_classifier</span><span class="o">.</span><span class="n">print_classes_dl</span><span class="p">()</span>
</pre></div>
</div>
<p>To see a sample batch, use the <code class="docutils literal notranslate"><span class="pre">show_sample</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">show_sample</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/show_sample_train_8.png"><img alt="../_images/show_sample_train_8.png" src="../_images/show_sample_train_8.png" style="width: 400px;" /></a>
<p>By default, this will show you the first batch created from your training datasest, along with corresponding batch information (<code class="docutils literal notranslate"><span class="pre">batch_info()</span></code>).
The <code class="docutils literal notranslate"><span class="pre">batch_number</span></code> and <code class="docutils literal notranslate"><span class="pre">set_name</span></code>  arguments can be used to show different batches and datasets, respectively:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">show_sample</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span> <span class="n">batch_number</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/show_sample_val_8.png"><img alt="../_images/show_sample_val_8.png" src="../_images/show_sample_val_8.png" style="width: 400px;" /></a>
</section>
</section>
<section id="load-a-pytorch-model">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Load a PyTorch model</a><a class="headerlink" href="#load-a-pytorch-model" title="Permalink to this heading"></a></h2>
<p>The <a class="reference external" href="https://pytorch.org/vision/stable/models.html">torchvision.models</a> subpackage contains a number of pre-trained models which can be loaded into your classifier.
These can be added in one of two ways:</p>
<blockquote>
<div><ol class="arabic">
<li><p>Import a model directly from <code class="docutils literal notranslate"><span class="pre">torchvision.models</span></code> and add to your classifier using your classifiers <code class="docutils literal notranslate"><span class="pre">.add_model</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">my_model</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># reshape the final layer (FC layer) of the neural network to output the same number of nodes as classes as in your dataset</span>
<span class="n">num_input_features</span><span class="o">=</span><span class="n">my_model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">my_model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_input_features</span><span class="p">,</span> <span class="n">my_classifier</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>

<span class="n">my_classifier</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span><span class="n">my_model</span><span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html">See this tutorial for further details on fine-tuning torchvision models</a></p>
</li>
<li><p>Using your classifiers <code class="docutils literal notranslate"><span class="pre">.initialize_model</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">initialize_model</span><span class="p">(</span><span class="s2">&quot;resnet18&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, this will initiliase a pretrained model and reshape the last layer to output the same number of nodes as classes in your dataset (as above).</p>
</li>
</ol>
</div></blockquote>
<section id="define-learning-rates-and-initialise-optimiser-and-scheduler">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Define learning rates and initialise optimiser and scheduler</a><a class="headerlink" href="#define-learning-rates-and-initialise-optimiser-and-scheduler" title="Permalink to this heading"></a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>not done yet - mostly copy &amp; pasted from tutorials</p>
</div>
<p>When training your model, you can either use one learning rate for all layers in your neural network or define layerwise learning rates (i.e. different learning rates for each layer in your neural network).
Normally, when fine-tuning pretrained models, layerwise learning rates are favoured, with smaller learning rates assigned to the first layers.</p>
<p>To define layerwise learning rates, use your classifiers <code class="docutils literal notranslate"><span class="pre">.layerwise_lr</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters_to_optimise</span> <span class="o">=</span> <span class="n">my_classifier</span><span class="o">.</span><span class="n">layerwise_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, a linear function is used to distribute the learning rates (using min_lr for the first layer and max_lr for the last layer).
This can be changed to a logarithmic function by specifying <code class="docutils literal notranslate"><span class="pre">ltype=&quot;geomspace&quot;</span></code>.</p>
<p>You should then initialise an optimiser that will optimise your desired parameters. This is done using your classifiers <code class="docutils literal notranslate"><span class="pre">.initialize_optimizer</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">initialise_optimizer</span><span class="p">(</span><span class="n">params2optim</span><span class="o">=</span><span class="n">parameters_to_optimise</span><span class="p">)</span>
</pre></div>
</div>
<p>By default,</p>
</section>
</section>
<section id="train-fine-tune-your-model">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Train/fine-tune your model</a><a class="headerlink" href="#train-fine-tune-your-model" title="Permalink to this heading"></a></h2>
<p>To begin training/fine-tuning your model, use your classifiers <code class="docutils literal notranslate"><span class="pre">.train</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>By default, this will run 25 epochs of training and validating your model and save your model in a newly created <code class="docutils literal notranslate"><span class="pre">./models</span></code> directory.
The <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> and <code class="docutils literal notranslate"><span class="pre">save_model_dir</span></code> arguments can be specified to change these:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">save_model_dir</span><span class="o">=</span><span class="s1">&#39;./path/to/models&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Other arguments you may want to specify when training your model include:</p>
<ul class="simple">
<li><p>phases: phases to perform at each epoch</p></li>
<li><p>tensorboard_path: directory to save tensorboard files</p></li>
<li><p>verbosity_level: -1 (quiet), 0 (normal), 1 (verbose), 2 (very verbose), 3 (debug)</p></li>
</ul>
<section id="plot-metrics">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Plot metrics</a><a class="headerlink" href="#plot-metrics" title="Permalink to this heading"></a></h3>
<p>Metrics are stored in a dictionary accesible via your classifiers <code class="docutils literal notranslate"><span class="pre">.metrics</span></code> method. To list these, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">myclassifier</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<p>To visualise the progress of your training, metrics can be plotted using <code class="docutils literal notranslate"><span class="pre">.plot_metric</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">plot_metric</span><span class="p">(</span><span class="n">y_axis</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;epoch_loss_train&quot;</span><span class="p">,</span> <span class="s2">&quot;epoch_loss_val&quot;</span><span class="p">],</span> <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">legends</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Train&quot;</span><span class="p">,</span> <span class="s2">&quot;Valid&quot;</span><span class="p">])</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/loss.png"><img alt="../_images/loss.png" src="../_images/loss.png" style="width: 400px;" /></a>
</section>
</section>
<section id="inference">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Inference</a><a class="headerlink" href="#inference" title="Permalink to this heading"></a></h2>
<p>Finally, to use your model for inference use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;your_set_name&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>e.g. to run the trained model on the test dataset, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_classifier</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">set_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Annotate.html" class="btn btn-neutral float-left" title="Annotate" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Post-process.html" class="btn btn-neutral float-right" title="Post-process" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, RW.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>