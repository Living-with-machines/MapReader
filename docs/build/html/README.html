<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Contents &mdash; MapReader 0.3.3 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="mapreader.utils.utils" href="api/mapreader/utils/utils/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MapReader
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Install.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="User-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://dl.acm.org/doi/10.1145/3557919.3565812">MapReader Paper</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Contents</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#gallery">Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="#what-is-mapreader">What is MapReader?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#set-up-a-conda-environment">Set up a conda environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#method-1">Method 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#method-2">Method 2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#use-cases">Use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-contribute">How to contribute</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-cite-mapreader">How to cite MapReader</a></li>
<li class="toctree-l1"><a class="reference internal" href="#credits-and-re-use-terms">Credits and re-use terms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#digitized-maps">Digitized maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metadata">Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="#acknowledgements">Acknowledgements</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MapReader</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Contents</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/README.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">br</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">p</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="n">MapReader</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">h2</span><span class="o">&gt;</span><span class="n">A</span> <span class="n">computer</span> <span class="n">vision</span> <span class="n">pipeline</span> <span class="k">for</span> <span class="n">exploring</span> <span class="ow">and</span> <span class="n">analyzing</span> <span class="n">images</span> <span class="n">at</span> <span class="n">scale</span><span class="o">&lt;/</span><span class="n">h2</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
<p align="center"></p><section id="contents">
<h1>Contents<a class="headerlink" href="#contents" title="Permalink to this heading"></a></h1>
<div class="toctree-wrapper compound">
</div>
<p><a class="reference external" href="#gallery">Gallery</a>
<a class="reference external" href="#what-is-mapreader">What is MapReader?</a>
<a class="reference external" href="#overview">Overview</a>
<a class="reference external" href="#use-cases">Use cases</a>
<a class="reference external" href="#how-to-contribute">How to contribute</a>
<a class="reference external" href="#how-to-cite-mapreader">How to cite MapReader</a>
<a class="reference external" href="#credits-and-re-use-terms">Credits and re-use terms</a></p>
<blockquote>
<div><p><a class="reference external" href="#digitized-maps">Digitized maps</a>: MapReader can retrieve maps
from NLS via tileserver. Read the re-use terms in this section.
<a class="reference external" href="#metadata">Metadata</a>: the metadata files are stored at
<a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/mapreader/persistent_data">mapreader/persistent_data</a>.
Read the re-use terms in this section.
<a class="reference external" href="#acknowledgements">Acknowledgements</a></p>
</div></blockquote>
</section>
<section id="gallery">
<h1>Gallery<a class="headerlink" href="#gallery" title="Permalink to this heading"></a></h1>
<div class="docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>classification_one
_inch_maps_001</strong><strong>Tutorial:</strong>
train/fine-tune PyTorch CV
classifiers on historical maps
(Fig: rail infrastructure around
London as predicted by a
MapReader model).</p></td>
<td><p><strong>classification_p
lant_phenotype</strong><strong>Tutorial:</strong>
train/fine-tune PyTorch CV
classifiers on plant patches in
images (plant phenotyping
example).</p></td>
</tr>
<tr class="row-even"><td><p><strong>classi
fication_mnist</strong><strong>Tutorial:</strong>
train/fine-tune PyTorch CV
classifiers on whole MNIST images
(not on patches/slices of those
images).</p></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>MapReader paper</strong></p>
</div>
</section>
<section id="what-is-mapreader">
<h1>What is MapReader?<a class="headerlink" href="#what-is-mapreader" title="Permalink to this heading"></a></h1>
<p>MapReader is an end-to-end computer vision (CV) pipeline for exploring
and analyzing images at scale.</p>
<p>MapReader was developed in the <a class="reference external" href="https://livingwithmachines.ac.uk/">Living with
Machines</a> project to analyze large
collections of historical maps but is a <strong>generalisable</strong> computer
vision pipeline which can be applied to <strong>any images</strong> in a wide variety
of domains. See <a class="reference external" href="#gallery">Gallery</a> for some examples.</p>
<p>Refer to each tutorial/example in the <a class="reference external" href="#use-cases">use cases</a> section
for more details on MapReader’s relevant functionalities for
<a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial">non-geospatial</a>
and
<a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial">geospatial</a>
images.</p>
</section>
<section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h1>
<p>MapReader is a groundbreaking interdisciplinary tool that emerged from a
specific set of geospatial historical research questions. It was
inspired by methods in biomedical imaging and geographic information
science, which were adapted for annotation and use by historians, for
example in <a class="reference external" href="https://doi.org/10.1093/jvcult/vcab009">JVC</a> and
<a class="reference external" href="https://arxiv.org/abs/2111.15592">MapReader</a> papers. The success of
the tool subsequently generated interest from plant phenotype
researchers working with large image datasets, and so MapReader is an
example of cross-pollination between the humanities and the sciences
made possible by reproducible data science.</p>
<p>MapReader has two main components: preprocessing/annotation and
training/inference as shown in this figure:</p>
<p align="center"></p><p>It provides a set of tools to:</p>
<ul class="simple">
<li><p><strong>load</strong> images or maps stored locally or <strong>retrieve</strong> maps via
web-servers (e.g., tileservers which can be used to retrieve maps
from OpenStreetMap (OSM), the National Library of Scotland (NLS), or
elsewhere). :warning: Refer to the <a class="reference external" href="#credits-and-re-use-terms">credits and re-use
terms</a> section if you are using
digitized maps or metadata provided by NLS.</p></li>
<li><p><strong>preprocess</strong> images or maps (e.g., divide them into patches,
resampling the images, removing borders outside the neatline or
reprojecting the map).</p></li>
<li><p>annotate images or maps or their patches (i.e. slices of an image or
map) using an <strong>interactive annotation tool</strong>.</p></li>
<li><p><strong>train, fine-tune, and evaluate</strong> various CV models.</p></li>
<li><p><strong>predict</strong> labels (i.e., model inference) on large sets of images or
maps.</p></li>
<li><p>Other functionalities include:</p>
<ul>
<li><p>various <strong>plotting tools</strong> using, e.g., <em>matplotlib</em>, <em>cartopy</em>,
<em>Google Earth</em>, and <a class="reference external" href="https://kepler.gl/">kepler.gl</a>.</p></li>
<li><p>compute mean/standard-deviation <strong>pixel intensity</strong> of image
patches.</p></li>
</ul>
</li>
</ul>
</section>
<section id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h1>
<section id="set-up-a-conda-environment">
<h2>Set up a conda environment<a class="headerlink" href="#set-up-a-conda-environment" title="Permalink to this heading"></a></h2>
<p>We recommend installation via Anaconda (refer to <a class="reference external" href="https://docs.anaconda.com/anaconda/install/">Anaconda website and
follow the
instructions</a>).</p>
<ul class="simple">
<li><p>Create a new environment for <code class="docutils literal notranslate"><span class="pre">mapreader</span></code> called <code class="docutils literal notranslate"><span class="pre">mr_py38</span></code>:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>mr_py38<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.8
</pre></div>
</div>
<ul class="simple">
<li><p>Activate the environment:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>mr_py38
</pre></div>
</div>
</section>
<section id="method-1">
<h2>Method 1<a class="headerlink" href="#method-1" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Install <code class="docutils literal notranslate"><span class="pre">mapreader</span></code>:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>mapreader
</pre></div>
</div>
<p>To work with geospatial images (e.g., maps):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;mapreader[geo]&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>We have provided some <a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples">Jupyter Notebooks to showcase MapReader’s
functionalities</a>.
To allow the newly created <code class="docutils literal notranslate"><span class="pre">mr_py38</span></code> environment to show up in the
notebooks:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>ipykernel<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>--name<span class="w"> </span>mr_py38<span class="w"> </span>--display-name<span class="w"> </span><span class="s2">&quot;Python (mr_py38)&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Continue with the examples in <a class="reference external" href="#use-cases">Use cases</a>!</p></li>
<li><p>⚠️ On <em>Windows</em> and for <em>geospatial images</em> (e.g., maps), you might
need to do:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># activate the environment</span>
conda<span class="w"> </span>activate<span class="w"> </span>mr_py38

<span class="c1"># install rasterio and fiona manually</span>
conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span><span class="nv">rasterio</span><span class="o">=</span><span class="m">1</span>.2.10
conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span><span class="nv">fiona</span><span class="o">=</span><span class="m">1</span>.8.20

<span class="c1"># install git</span>
conda<span class="w"> </span>install<span class="w"> </span>git

<span class="c1"># install MapReader</span>
pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/Living-with-machines/MapReader.git

<span class="c1"># open Jupyter Notebook (if you want to test/work with the notebooks in &quot;examples&quot; directory)</span>
<span class="nb">cd</span><span class="w"> </span>/path/to/MapReader
jupyter<span class="w"> </span>notebook
</pre></div>
</div>
</section>
<section id="method-2">
<h2>Method 2<a class="headerlink" href="#method-2" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Clone <code class="docutils literal notranslate"><span class="pre">mapreader</span></code> source code:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/Living-with-machines/MapReader.git
</pre></div>
</div>
<ul class="simple">
<li><p>Install:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/MapReader
pip<span class="w"> </span>install<span class="w"> </span>-v<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
<p>To work with geospatial images (e.g., maps):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/MapReader
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.<span class="s2">&quot;[geo]&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>We have provided some <a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples">Jupyter Notebooks to showcase MapReader’s
functionalities</a>.
To allow the newly created <code class="docutils literal notranslate"><span class="pre">mr_py38</span></code> environment to show up in the
notebooks:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>ipykernel<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>--name<span class="w"> </span>mr_py38<span class="w"> </span>--display-name<span class="w"> </span><span class="s2">&quot;Python (mr_py38)&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Continue with the examples in <a class="reference external" href="#use-cases">Use cases</a>!</p></li>
</ul>
</section>
</section>
<section id="use-cases">
<h1>Use cases<a class="headerlink" href="#use-cases" title="Permalink to this heading"></a></h1>
<p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples">Tutorials</a>
are organized in Jupyter Notebooks. Follow the hyperlinks on input type
names (“Non-Geospatial” or “Geospatial”) to read guidance specific to
those image types.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial">Non-Geospatial</a>:</p>
<ul>
<li><p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_plant_phenotype">classification_plant_phenotype</a></p>
<ul>
<li><p><strong>Goal:</strong> train/fine-tune PyTorch CV classifiers on plant
patches in images (plant phenotyping example).</p></li>
<li><p><strong>Dataset:</strong> Example images taken from the openly accessible
<code class="docutils literal notranslate"><span class="pre">CVPPP2014_LSV_training_data</span></code> dataset available from
<a class="reference external" href="https://www.plant-phenotyping.org/datasets-download">https://www.plant-phenotyping.org/datasets-download</a>.</p></li>
<li><p><strong>Data access:</strong> locally stored</p></li>
<li><p><strong>Annotations</strong> are done on plant patches (i.e., slices of each
plant image).</p></li>
<li><p><strong>Classifier:</strong> train/fine-tuned PyTorch CV models.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_mnist">classification_mnist</a></p>
<ul>
<li><p><strong>Goal:</strong> train/fine-tune PyTorch CV classifiers on MNIST.</p></li>
<li><p><strong>Dataset:</strong> Example images taken from
<a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>.</p></li>
<li><p><strong>Data access:</strong> locally stored</p></li>
<li><p><strong>Annotations</strong> are done on whole MNIST images, <strong>not</strong> on
patches/slices of those images.</p></li>
<li><p><strong>Classifier:</strong> train/fine-tuned PyTorch CV models.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial">Geospatial</a>:</p>
<ul>
<li><p>Maps:</p>
<ul>
<li><p><a class="reference external" href="https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial/classification_one_inch_maps_001">classification_one_inch_maps_001</a></p>
<ul>
<li><p><strong>Goal:</strong> train/fine-tune PyTorch CV classifiers on
historical maps.</p></li>
<li><p><strong>Dataset:</strong> from National Library of Scotland: <a class="reference external" href="https://mapseries-tilesets.s3.amazonaws.com/1inch_2nd_ed/index.html">OS
one-inch, 2nd edition
layer</a>.</p></li>
<li><p><strong>Data access:</strong> tileserver</p></li>
<li><p><strong>Annotations</strong> are done on map patches (i.e., slices of
each map).</p></li>
<li><p><strong>Classifier:</strong> train/fine-tuned PyTorch CV models.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="how-to-contribute">
<h1>How to contribute<a class="headerlink" href="#how-to-contribute" title="Permalink to this heading"></a></h1>
<p>We welcome contributions related to new applications, both with
geospatial images (other maps, remote sensing data, aerial photography)
and non-geospatial images (for example, other scientific image
datasets).</p>
</section>
<section id="how-to-cite-mapreader">
<h1>How to cite MapReader<a class="headerlink" href="#how-to-cite-mapreader" title="Permalink to this heading"></a></h1>
<p>Please consider acknowledging MapReader if it helps you to obtain
results and figures for publications or presentations, by citing:</p>
<p>Link: <a class="reference external" href="https://dl.acm.org/doi/10.1145/3557919.3565812">https://dl.acm.org/doi/10.1145/3557919.3565812</a></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Kasra Hosseini, Daniel C. S. Wilson, Kaspar Beelen, and Katherine McDonough. 2022. MapReader: a computer vision pipeline for the semantic exploration of maps at scale. In Proceedings of the 6th ACM SIGSPATIAL International Workshop on Geospatial Humanities (GeoHumanities &#39;22). Association for Computing Machinery, New York, NY, USA, 8–19. https://doi.org/10.1145/3557919.3565812
</pre></div>
</div>
<p>and in BibTeX:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3557919.3565812</span><span class="p">,</span>
<span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Hosseini, Kasra and Wilson, Daniel C. S. and Beelen, Kaspar and McDonough, Katherine}</span><span class="p">,</span>
<span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{MapReader: A Computer Vision Pipeline for the Semantic Exploration of Maps at Scale}</span><span class="p">,</span>
<span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2022}</span><span class="p">,</span>
<span class="na">isbn</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{9781450395335}</span><span class="p">,</span>
<span class="na">publisher</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
<span class="na">address</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{New York, NY, USA}</span><span class="p">,</span>
<span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://doi.org/10.1145/3557919.3565812}</span><span class="p">,</span>
<span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1145/3557919.3565812}</span><span class="p">,</span>
<span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the 6th ACM SIGSPATIAL International Workshop on Geospatial Humanities}</span><span class="p">,</span>
<span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{8–19}</span><span class="p">,</span>
<span class="na">numpages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{12}</span><span class="p">,</span>
<span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{supervised learning, historical maps, deep learning, digital libraries and archives, computer vision, classification}</span><span class="p">,</span>
<span class="na">location</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Seattle, Washington}</span><span class="p">,</span>
<span class="na">series</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{GeoHumanities &#39;22}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="credits-and-re-use-terms">
<h1>Credits and re-use terms<a class="headerlink" href="#credits-and-re-use-terms" title="Permalink to this heading"></a></h1>
<section id="digitized-maps">
<h2>Digitized maps<a class="headerlink" href="#digitized-maps" title="Permalink to this heading"></a></h2>
<p>MapReader can retrieve maps from NLS (National Library of Scotland) via
webservers. For all the digitized maps (retrieved or locally stored),
please note the re-use terms:</p>
<dl class="field-list simple">
<dt class="field-odd">warning</dt>
<dd class="field-odd"><p>Use of the digitised maps for commercial purposes is currently</p>
</dd>
</dl>
<p>restricted by contract. Use of these digitised maps for non-commercial
purposes is permitted under the <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
Attribution-NonCommercial-ShareAlike 4.0
International</a>
(CC-BY-NC-SA) licence. Please refer to
<a class="reference external" href="https://maps.nls.uk/copyright.html#exceptions-os">https://maps.nls.uk/copyright.html#exceptions-os</a> for details on
copyright and re-use license.</p>
</section>
<section id="metadata">
<h2>Metadata<a class="headerlink" href="#metadata" title="Permalink to this heading"></a></h2>
<p>We have provided some metadata files in <code class="docutils literal notranslate"><span class="pre">mapreader/persistent_data</span></code>.
For all these file, please note the re-use terms:</p>
<dl class="field-list simple">
<dt class="field-odd">warning</dt>
<dd class="field-odd"><p>Use of the metadata for commercial purposes is currently</p>
</dd>
</dl>
<p>restricted by contract. Use of this metadata for non-commercial purposes
is permitted under the <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
Attribution-NonCommercial-ShareAlike 4.0
International</a>
(CC-BY-NC-SA) licence. Please refer to
<a class="reference external" href="https://maps.nls.uk/copyright.html#exceptions-os">https://maps.nls.uk/copyright.html#exceptions-os</a> for details on
copyright and re-use license.</p>
</section>
<section id="acknowledgements">
<h2>Acknowledgements<a class="headerlink" href="#acknowledgements" title="Permalink to this heading"></a></h2>
<p>This work was supported by Living with Machines (AHRC grant
AH/S01179X/1) and The Alan Turing Institute (EPSRC grant EP/N510129/1).
Living with Machines, funded by the UK Research and Innovation (UKRI)
Strategic Priority Fund, is a multidisciplinary collaboration delivered
by the Arts and Humanities Research Council (AHRC), with The Alan Turing
Institute, the British Library and the Universities of Cambridge, East
Anglia, Exeter, and Queen Mary University of London.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api/mapreader/utils/utils/index.html" class="btn btn-neutral float-left" title="mapreader.utils.utils" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, RW.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>