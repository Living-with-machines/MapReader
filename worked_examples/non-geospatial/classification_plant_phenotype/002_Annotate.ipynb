{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate\n",
    "https://mapreader.readthedocs.io/en/latest/User-guide/Annotate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to first edit `./annotation_tasks.yaml` file! It should look something like this:\n",
    "\n",
    "```yaml\n",
    "# ---------------------------------------\n",
    "# Define an annotation task\n",
    "# This includes:\n",
    "# 1. a name (e.g., building_simple or rail_space, see below)\n",
    "# 2. a list of labels to be used for this task\n",
    "# ---------------------------------------\n",
    "tasks:\n",
    "  building_simple:\n",
    "    labels: [\"No\", \"building\"]\n",
    "  rail_space:\n",
    "    labels: [\"No\", \"rail space\"]\n",
    "\n",
    "# ---------------------------------------\n",
    "# paths\n",
    "# You need to specify:\n",
    "# 1. a name (e.g., task_test_one_inch_maps_001, see below)\n",
    "# 2. patch_paths: path to all the patches to be annotated\n",
    "# 3. parent_paths: path to the original/parent maps/images (which were patchified)\n",
    "# 4. annot_dir: directory in which the outputs will be stored\n",
    "# ---------------------------------------\n",
    "paths:\n",
    "  task_test_one_inch_maps_001:\n",
    "    patch_paths: \"./maps_tutorial/slice_50_50/patch-*PNG\"\n",
    "    parent_paths: \"./maps_tutorial/*png\"\n",
    "    annot_dir: \"./annotations_one_inch\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader.annotate.utils import prepare_annotation, save_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "[INFO] calculate pixel stats for image: 2014-06-06_plant001_rgb.png\n",
      "----------\n",
      "[INFO] calculate pixel stats for image: 2014-07-17_plant047_rgb.png\n",
      "Number of already annotated images: 124\n",
      "Number of images to be annotated (total): 96\n",
      "[INFO] len(df) = 96, .sample method is deactivated.\n",
      "Number of images to annotate (current batch): 96\n"
     ]
    }
   ],
   "source": [
    "userID = \"kasra\"\n",
    "annotation_tasks_file = \"./annotation_tasks_open.yaml\"\n",
    "task = \"phenotype_test\"\n",
    "annotation_set = \"task_test_phenotype\"\n",
    "\n",
    "# sortby=\"mean\" sorts the patches according to the mean pixel intensities\n",
    "# xoffset and yoffset specify the border size around a patch to be used as the context image (in pixel)\n",
    "annotate = prepare_annotation(userID, \n",
    "                            task, \n",
    "                            annotation_tasks_file=annotation_tasks_file,\n",
    "                            annotation_set=annotation_set,\n",
    "                            sortby='mean',\n",
    "                            min_alpha_channel=0.01,\n",
    "                            xoffset=50, \n",
    "                            yoffset=50,\n",
    "                            context_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate maps and save annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ad5531f00540eb8acf9c927578492d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Annotation(canvas=OutputCanvas(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 6â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Save 0 new annotations to ./annotations_phenotype_open_access/phenotype_test_#kasra#.csv\n",
      "[INFO] 0 labels were not already stored\n",
      "[INFO] Total number of annotations: 124\n"
     ]
    }
   ],
   "source": [
    "save_annotation(annotate, \n",
    "                userID, \n",
    "                task, \n",
    "                annotation_tasks_file=annotation_tasks_file,\n",
    "                annotation_set=annotation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mr_py38)",
   "language": "python",
   "name": "mr_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
