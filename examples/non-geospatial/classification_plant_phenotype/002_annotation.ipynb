{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation\n",
    "\n",
    "(You can skip this step if you already have annotated patches and/or have a pre-trained `MapReader` model.)\n",
    "\n",
    "`MapReader` provides a flexible way to set-up a new annotation task, summarized in the following three steps:\n",
    "\n",
    "1. Edit `./annotation_tasks_open.yaml` file. There are two sections in this file: `tasks` and `paths`. In the `tasks` section, you need to specify a task and its labels. For example:\n",
    "\n",
    "```yaml\n",
    "# ---------------------------------------\n",
    "# Define an annotation task\n",
    "# This includes:\n",
    "# 1. a name (e.g., building_simple or rail_space, see below)\n",
    "# 2. a list of labels to be used for this task\n",
    "# ---------------------------------------\n",
    "tasks:\n",
    "  building_simple:\n",
    "    labels: [\"No\", \"building\"]\n",
    "  rail_space:\n",
    "    labels: [\"No\", \"rail space\"]\n",
    "```\n",
    "\n",
    "Here, the name of a task is `building_simple` with two labels, and the other one is `rail_space` also with two labels. These are just examples. You can have as many tasks or labels (e.g., for multiclass classification) as you want!\n",
    "\n",
    "In the `paths` section:\n",
    "\n",
    "```yaml\n",
    "# ---------------------------------------\n",
    "# paths\n",
    "# You need to specify:\n",
    "# 1. a name (e.g., task_test_one_inch_maps_001, see below)\n",
    "# 2. patch_paths: path to all the patches to be annotated\n",
    "# 3. parent_paths: path to the original/parent maps/images (which were patchified)\n",
    "# 4. annot_dir: directory in which the outputs will be stored\n",
    "# ---------------------------------------\n",
    "paths:\n",
    "  task_test_one_inch_maps_001:\n",
    "    patch_paths: \"./maps_tutorial/slice_50_50/patch-*PNG\"\n",
    "    parent_paths: \"./maps_tutorial/*png\"\n",
    "    annot_dir: \"./annotations_one_inch\"\n",
    "```\n",
    "\n",
    "We give a name to the annotation set: `task_test_one_inch_maps_001`; slices/patches to be annotated are stored in `patch_paths` (note the wildcard `*`); the main/parent image files are stored in `parent_paths`; and we want to store the results of annotations in `annot_dir`.\n",
    "\n",
    "2. In the `Inputs` cell (below), enter a `userID` (e.g., your name), pick a `task` and `annotation_set` specified in the yaml file in step 1.\n",
    "\n",
    "3. Do not forget to save the annotations. You can save the annotations at any time, and next time, you will continue from where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader.annotate.utils import prepare_annotation, save_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "[INFO] calculate pixel stats for image: 2014-06-06_plant001_rgb.png\n",
      "----------\n",
      "[INFO] calculate pixel stats for image: 2014-07-17_plant047_rgb.png\n",
      "Number of images to annotate (current batch): 100\n"
     ]
    }
   ],
   "source": [
    "userID = \"rw\"\n",
    "# yaml file, list of tasks/paths\n",
    "annotation_tasks_file = \"./annotation_tasks_open.yaml\"\n",
    "# Pick one of the tasks in the yaml file\n",
    "task = \"phenotype_test\"\n",
    "# This is the name given to the annotation set in the yaml file\n",
    "annotation_set = \"task_test_phenotype\"\n",
    "\n",
    "# sortby=\"mean\" sorts the patches according to the mean pixel intensities\n",
    "# xoffset and yoffset specify the border size around a patch to be used as the context image (in pixel)\n",
    "annotation = prepare_annotation(userID, \n",
    "                                task, \n",
    "                                annotation_tasks_file=annotation_tasks_file,\n",
    "                                annotation_set=annotation_set,\n",
    "                                sortby=\"mean\",\n",
    "                                # only show patches with alpha >= min_alpha_channel\n",
    "                                min_alpha_channel=0.01,\n",
    "                                xoffset=50,\n",
    "                                yoffset=50,\n",
    "                                context_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start annotating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** in some of our experiments, when we used the keyboard shortcuts (e.g., 1, 2 or j and k, see below), two images were annotated in a row while only one patch should have been annotated. In such cases, the issue was resolved by stopping and restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f44529ef2484d75a19f5943fc3bfd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Annotation(canvas=OutputCanvas(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 6â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Save 100 new annotations to ./annotations_phenotype_open_access/phenotype_test_#rw#.csv\n",
      "[INFO] 100 labels were not already stored\n",
      "[INFO] Total number of annotations: 100\n"
     ]
    }
   ],
   "source": [
    "save_annotation(annotation, \n",
    "                userID, \n",
    "                task, \n",
    "                annotation_tasks_file=annotation_tasks_file,\n",
    "                annotation_set=annotation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mr_py38)",
   "language": "python",
   "name": "mr_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
