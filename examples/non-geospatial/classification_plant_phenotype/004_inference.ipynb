{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference\n",
    "\n",
    "In the previous notebook, we saw how to do model inference on the test set. Here, we show how to load an already trained/fine-tuned model and a dataset and then do model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve issue with autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import loader\n",
    "from mapreader import classifier\n",
    "from mapreader import load_patches\n",
    "from mapreader import patchTorchDataset\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "##from scipy.interpolate import griddata\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read patches (i.e., sliced images) and add metadata\n",
    "\n",
    "First, we need to load a set of images/pathces. We use a CV model to do inference on these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimgs = load_patches(\"./dataset/eg_slice_50_50/*PNG\", \n",
    "                      parent_paths=\"./dataset/open_access_plant/*png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pd, patches_pd = myimgs.convertImages(fmt=\"dataframe\")\n",
    "patches_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `.add_metadata`:\n",
    "\n",
    "```python\n",
    "# remove duplicates using \"name\" column\n",
    "if columns == None:\n",
    "    columns = list(metadata_df.columns)\n",
    "\n",
    "if (\"name\" in columns) and (\"image_id\" in columns):\n",
    "    print(f\"Both 'name' and 'image_id' columns exist! Use 'name' to index.\")\n",
    "    image_id_col = \"name\"\n",
    "if \"name\" in columns:\n",
    "    image_id_col = \"name\"\n",
    "elif \"image_id\" in columns:\n",
    "    image_id_col = \"image_id\"\n",
    "else:\n",
    "    raise ValueError(\"'name' or 'image_id' should be one of the columns.\")\n",
    "```\n",
    "\n",
    "The dataframe should have either `name` or `image_id` column, and that column should be the image ID (NOT the path to the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename image_path to image_id\n",
    "# This is needed later (see `.add_metadata`)\n",
    "patches_pd = patches_pd.reset_index()\n",
    "patches_pd.rename(columns={\"index\": \"image_id\"}, \n",
    "                  inplace=True)\n",
    "patches_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches2infer = patches_pd[[\"image_path\"]]\n",
    "patches2infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add patches to `patchTorchDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# --- Transformation\n",
    "# ------------------\n",
    "# FOR INCEPTION\n",
    "#resize2 = 299\n",
    "# otherwise:\n",
    "resize2 = 224\n",
    "\n",
    "# mean and standard deviations of pixel intensities in \n",
    "# all the patches in 6\", second edition maps\n",
    "normalize_mean = 1 - np.array([0.82860442, 0.82515008, 0.77019864])\n",
    "normalize_std = 1 - np.array([0.1025585, 0.10527616, 0.10039222])\n",
    "# other options:\n",
    "# normalize_mean = [0.485, 0.456, 0.406]\n",
    "# normalize_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms = {\n",
    "    'val': transforms.Compose(\n",
    "        [transforms.Resize((resize2, resize2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std)\n",
    "        ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches2infer_dataset = patchTorchDataset(patches2infer, \n",
    "                                          transform=data_transforms[\"val\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a classifier (normally trained in notebook 003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclassifier = classifier(device=\"default\")\n",
    "\n",
    "# HERE, you need to load a model stored in ./models_plant_open/\n",
    "# e.g., \n",
    "# myclassifier.load(\"./models_plant_open/checkpoint_9.pkl\")\n",
    "myclassifier.load(\"./models_plant_open/INSERT_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset to myclassifier\n",
    "batch_size=64\n",
    "myclassifier.add2dataloader(patches2infer_dataset, \n",
    "                            set_name=\"infer_test\", \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False, \n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inference on `set_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myclassifier.inference(set_name=\"infer_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclassifier.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclassifier.inference_sample_results(num_samples=8, \n",
    "                                      class_index=0, \n",
    "                                      set_name=\"infer_test\",\n",
    "                                      min_conf=50,\n",
    "                                      max_conf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add model inference outputs to `myimgs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches2infer['pred'] = myclassifier.pred_label\n",
    "patches2infer['conf'] = np.max(np.array(myclassifier.pred_conf), \n",
    "                               axis=1)\n",
    "patches2infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_pd = \\\n",
    "    patches_pd.merge(patches2infer, \n",
    "                     how=\"outer\",\n",
    "                     on=\"image_path\",\n",
    "                     validate=\"1:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimgs.add_metadata(patches_pd, \n",
    "                    tree_level=\"child\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write outputs as CSVs, one file per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pd, patches_pd = myimgs.convertImages(fmt=\"dataframe\")\n",
    "patches_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pd[\"name\"] = imgs_pd[\"image_path\"].apply(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./infer_output_open_plant\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_img in list(imgs_pd.index):\n",
    "    # --- paths\n",
    "    img_name = one_img.split(\".\")[0]\n",
    "    patch2write = os.path.join(output_dir, f\"patch_{img_name}.csv\")\n",
    "    sheet2write = os.path.join(output_dir, f\"sheet_{img_name}.csv\")\n",
    "    # --- write outputs\n",
    "    patches_pd[patches_pd[\"parent_id\"] == one_img].to_csv(patch2write, index=False)\n",
    "    imgs_pd[imgs_pd.index == one_img].to_csv(sheet2write, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load outputs and plot\n",
    "\n",
    "Although we already have all the required dataframes/variables loaded, we re-load them here as this is a required step in most realistic applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimgs = load_patches(\"./dataset/eg_slice_50_50/*PNG\", \n",
    "                      parent_paths=\"./dataset/open_access_plant/*png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CSV files which contain predictions/confidence/...\n",
    "path2patch = glob.glob(\"./infer_output_open_plant/*csv\")\n",
    "\n",
    "for path2metadata in path2patch:\n",
    "    print(path2metadata)\n",
    "    myimgs.add_metadata(metadata=path2metadata, \n",
    "                        tree_level=\"child\", \n",
    "                        delimiter=\",\")\n",
    "\n",
    "# or directly:\n",
    "# myimgs.add_metadata(patches_pd, tree_level=\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all parents\n",
    "all_parents = myimgs.list_parents()\n",
    "\n",
    "myimgs.show_par(all_parents[1], \n",
    "                value=\"pred\",\n",
    "                border=None,\n",
    "                plot_parent=True,\n",
    "                vmin=0, vmax=1,\n",
    "                figsize=(20, 20),\n",
    "                alpha=0.5, \n",
    "                colorbar=\"inferno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pd, patches_pd = myimgs.convertImages(fmt=\"dataframe\")\n",
    "print(len(patches_pd))\n",
    "patches_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter patches with NaNs\n",
    "patches_filt = patches_pd[~patches_pd[\"pred\"].isna()]\n",
    "patches_filt = patches_pd[patches_pd[\"pred\"] >= 0]\n",
    "patches_filt[\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
